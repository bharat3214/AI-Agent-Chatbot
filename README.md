# ğŸ¤– AI-Agent-Chatbot  
ğŸš€ An AI chatbot that supports multiple LLMs (**Groq, OpenAI**) with real-time interaction using **LangGraph** and **Streamlit**. It also features **web search integration** for enhanced responses.


ğŸ”— Live Demo
https://ai-agent-chatbot-gx858dcf2nixnzclkvhwwa.streamlit.app/



## ğŸ“Œ Features
- ğŸ§  Supports **Groq** (`Llama3`, `Mixtral`) and **OpenAI** (`GPT-4o-mini`)
- ğŸŒ **Optional Web Search** (Tavily API) for better responses
- âš¡ **Streamlit UI** for a smooth user experience
- ğŸ”— **FastAPI Backend** for handling AI agent interactions
- ğŸ”’ Uses **.env** for API key security

---

## ğŸ› ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repo  
```sh
git clone https://github.com/your-username/AI-Agent-Chatbot.git
cd AI-Agent-Chatbot
```

### 2ï¸âƒ£ Create a Virtual Environment  
```sh
python -m venv venv
source venv/bin/activate  # For MacOS/Linux
venv\Scripts\activate      # For Windows
```

### 3ï¸âƒ£ Install Dependencies  
```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up Environment Variables  
Create a `.env` file in the root directory and add:  
```
GROQ_API_KEY=your_groq_api_key
TAVILY_API_KEY=your_tavily_api_key
OPENAI_API_KEY=your_openai_api_key
```

### 5ï¸âƒ£ Start the Backend (FastAPI)
```sh
uvicorn backend:app --host 127.0.0.1 --port 8000 --reload
```

### 6ï¸âƒ£ Run the Frontend (Streamlit)
```sh
streamlit run frontend.py
```

---

## ğŸ”¥ Usage
1. Enter a **system prompt** to define the chatbotâ€™s behavior.
2. Choose **Groq** or **OpenAI** as the LLM provider.
3. Enable **Web Search** if required.
4. Ask your question and get an instant AI response!

---

## ğŸ“œ Technologies Used
- **Backend:** FastAPI, LangChain, LangGraph
- **Frontend:** Streamlit
- **LLMs:** Groq, OpenAI
- **Web Search:** Tavily API

---

## ğŸ¯ Future Enhancements
- [ ] Add more LLM providers (Anthropic, Mistral, etc.)
- [ ] Implement memory for multi-turn conversations
- [ ] Deploy on cloud (Render, Hugging Face Spaces, etc.)

---
